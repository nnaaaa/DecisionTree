digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname="helvetica"] ;
edge [fontname="helvetica"] ;
0 [label="a1 <= 0.5\nentropy = 1.22\nsamples = 54045\nvalue = [5178, 13327, 35540]\nclass = win", fillcolor="#ba93f1"] ;
1 [label="g1 <= 0.5\nentropy = 1.278\nsamples = 37804\nvalue = [3618, 11107, 23079]\nclass = win", fillcolor="#c6a6f3"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label="d2 <= 0.5\nentropy = 1.315\nsamples = 26342\nvalue = [2418, 9196, 14728]\nclass = win", fillcolor="#d6bff7"] ;
1 -> 2 ;
3 [label="d1 <= -0.5\nentropy = 1.316\nsamples = 21459\nvalue = [2228, 6690, 12541]\nclass = win", fillcolor="#cdb1f5"] ;
2 -> 3 ;
4 [label="d3 <= 0.5\nentropy = 1.036\nsamples = 4395\nvalue = [333, 774, 3288]\nclass = win", fillcolor="#a876ed"] ;
3 -> 4 ;
5 [label="d2 <= -0.5\nentropy = 0.913\nsamples = 3691\nvalue = [255, 491, 2945]\nclass = win", fillcolor="#9e67eb"] ;
4 -> 5 ;
6 [label="entropy = 0.153\nsamples = 853\nvalue = [7, 9, 837]\nclass = win", fillcolor="#833de5"] ;
5 -> 6 ;
7 [label="entropy = 1.06\nsamples = 2838\nvalue = [248, 482, 2108]\nclass = win", fillcolor="#a876ed"] ;
5 -> 7 ;
8 [label="d4 <= 0.5\nentropy = 1.386\nsamples = 704\nvalue = [78, 283, 343]\nclass = win", fillcolor="#ede3fb"] ;
4 -> 8 ;
9 [label="entropy = 1.383\nsamples = 528\nvalue = [77, 150, 301]\nclass = win", fillcolor="#cdb0f5"] ;
8 -> 9 ;
10 [label="entropy = 0.841\nsamples = 176\nvalue = [1, 133, 42]\nclass = loss", fillcolor="#79eda9"] ;
8 -> 10 ;
11 [label="c3 <= 0.5\nentropy = 1.361\nsamples = 17064\nvalue = [1895, 5916, 9253]\nclass = win", fillcolor="#d9c4f7"] ;
3 -> 11 ;
12 [label="c2 <= -0.5\nentropy = 1.332\nsamples = 14420\nvalue = [1567, 4554, 8299]\nclass = win", fillcolor="#cfb4f5"] ;
11 -> 12 ;
13 [label="entropy = 0.701\nsamples = 1833\nvalue = [92, 156, 1585]\nclass = win", fillcolor="#9456e9"] ;
12 -> 13 ;
14 [label="entropy = 1.376\nsamples = 12587\nvalue = [1475, 4398, 6714]\nclass = win", fillcolor="#dbc7f8"] ;
12 -> 14 ;
15 [label="e2 <= -0.5\nentropy = 1.397\nsamples = 2644\nvalue = [328, 1362, 954]\nclass = loss", fillcolor="#cff9e1"] ;
11 -> 15 ;
16 [label="entropy = 1.062\nsamples = 271\nvalue = [20, 52, 199]\nclass = win", fillcolor="#aa7aee"] ;
15 -> 16 ;
17 [label="entropy = 1.381\nsamples = 2373\nvalue = [308, 1310, 755]\nclass = loss", fillcolor="#bbf6d4"] ;
15 -> 17 ;
18 [label="d3 <= -0.5\nentropy = 1.195\nsamples = 4883\nvalue = [190, 2506, 2187]\nclass = loss", fillcolor="#e8fcf0"] ;
2 -> 18 ;
19 [label="d1 <= 0.0\nentropy = 1.085\nsamples = 1539\nvalue = [45, 502, 992]\nclass = win", fillcolor="#c3a1f3"] ;
18 -> 19 ;
20 [label="d4 <= 0.5\nentropy = 0.838\nsamples = 739\nvalue = [23, 122, 594]\nclass = win", fillcolor="#9f68eb"] ;
19 -> 20 ;
21 [label="entropy = 0.604\nsamples = 497\nvalue = [10, 49, 438]\nclass = win", fillcolor="#9253e8"] ;
20 -> 21 ;
22 [label="entropy = 1.157\nsamples = 242\nvalue = [13, 73, 156]\nclass = win", fillcolor="#c19ef2"] ;
20 -> 22 ;
23 [label="b1 <= 0.5\nentropy = 1.154\nsamples = 800\nvalue = [22, 380, 398]\nclass = win", fillcolor="#faf7fe"] ;
19 -> 23 ;
24 [label="entropy = 1.129\nsamples = 651\nvalue = [15, 348, 288]\nclass = loss", fillcolor="#defbea"] ;
23 -> 24 ;
25 [label="entropy = 1.007\nsamples = 149\nvalue = [7, 32, 110]\nclass = win", fillcolor="#ab7bee"] ;
23 -> 25 ;
26 [label="d1 <= 0.0\nentropy = 1.17\nsamples = 3344\nvalue = [145, 2004, 1195]\nclass = loss", fillcolor="#b4f5d0"] ;
18 -> 26 ;
27 [label="f1 <= 0.5\nentropy = 1.252\nsamples = 1788\nvalue = [99, 881, 808]\nclass = loss", fillcolor="#f0fdf6"] ;
26 -> 27 ;
28 [label="entropy = 1.2\nsamples = 1165\nvalue = [54, 659, 452]\nclass = loss", fillcolor="#c6f7da"] ;
27 -> 28 ;
29 [label="entropy = 1.266\nsamples = 623\nvalue = [45, 222, 356]\nclass = win", fillcolor="#d5bdf6"] ;
27 -> 29 ;
30 [label="c2 <= -0.5\nentropy = 0.989\nsamples = 1556\nvalue = [46, 1123, 387]\nclass = loss", fillcolor="#82efb0"] ;
26 -> 30 ;
31 [label="entropy = 1.173\nsamples = 371\nvalue = [12, 175, 184]\nclass = win", fillcolor="#f9f6fe"] ;
30 -> 31 ;
32 [label="entropy = 0.841\nsamples = 1185\nvalue = [34, 948, 203]\nclass = loss", fillcolor="#69eb9f"] ;
30 -> 32 ;
33 [label="g2 <= -0.5\nentropy = 1.105\nsamples = 11462\nvalue = [1200, 1911, 8351]\nclass = win", fillcolor="#aa79ed"] ;
1 -> 33 ;
34 [label="d1 <= 0.5\nentropy = 1.356\nsamples = 3692\nvalue = [556, 929, 2207]\nclass = win", fillcolor="#c5a3f3"] ;
33 -> 34 ;
35 [label="g3 <= 0.5\nentropy = 1.283\nsamples = 2935\nvalue = [451, 581, 1903]\nclass = win", fillcolor="#b890f0"] ;
34 -> 35 ;
36 [label="c2 <= 0.5\nentropy = 1.397\nsamples = 2004\nvalue = [355, 492, 1157]\nclass = win", fillcolor="#c8a8f4"] ;
35 -> 36 ;
37 [label="entropy = 1.378\nsamples = 1516\nvalue = [315, 298, 903]\nclass = win", fillcolor="#c19ef2"] ;
36 -> 37 ;
38 [label="entropy = 1.315\nsamples = 488\nvalue = [40, 194, 254]\nclass = win", fillcolor="#e5d7fa"] ;
36 -> 38 ;
39 [label="c3 <= 0.5\nentropy = 0.918\nsamples = 931\nvalue = [96, 89, 746]\nclass = win", fillcolor="#9d65eb"] ;
35 -> 39 ;
40 [label="entropy = 0.828\nsamples = 873\nvalue = [83, 66, 724]\nclass = win", fillcolor="#995eea"] ;
39 -> 40 ;
41 [label="entropy = 1.543\nsamples = 58\nvalue = [13, 23, 22]\nclass = loss", fillcolor="#fafefc"] ;
39 -> 41 ;
42 [label="a1 <= -0.5\nentropy = 1.439\nsamples = 757\nvalue = [105, 348, 304]\nclass = loss", fillcolor="#ecfcf3"] ;
34 -> 42 ;
43 [label="d2 <= -0.5\nentropy = 1.327\nsamples = 333\nvalue = [56, 208, 69]\nclass = loss", fillcolor="#97f1bd"] ;
42 -> 43 ;
44 [label="entropy = 1.577\nsamples = 77\nvalue = [22, 27, 28]\nclass = win", fillcolor="#fcfbfe"] ;
43 -> 44 ;
45 [label="entropy = 1.164\nsamples = 256\nvalue = [34, 181, 41]\nclass = loss", fillcolor="#7eeead"] ;
43 -> 45 ;
46 [label="c1 <= 0.5\nentropy = 1.36\nsamples = 424\nvalue = [49, 140, 235]\nclass = win", fillcolor="#d5bdf6"] ;
42 -> 46 ;
47 [label="entropy = 1.383\nsamples = 370\nvalue = [42, 140, 188]\nclass = win", fillcolor="#e5d6fa"] ;
46 -> 47 ;
48 [label="entropy = 0.556\nsamples = 54\nvalue = [7, 0, 47]\nclass = win", fillcolor="#9456e9"] ;
46 -> 48 ;
49 [label="d3 <= 0.5\nentropy = 0.943\nsamples = 7770\nvalue = [644, 982, 6144]\nclass = win", fillcolor="#9f68eb"] ;
33 -> 49 ;
50 [label="d2 <= -0.5\nentropy = 0.88\nsamples = 7282\nvalue = [548, 821, 5913]\nclass = win", fillcolor="#9c63eb"] ;
49 -> 50 ;
51 [label="d1 <= 0.0\nentropy = 0.243\nsamples = 897\nvalue = [24, 7, 866]\nclass = win", fillcolor="#8540e6"] ;
50 -> 51 ;
52 [label="entropy = 0.0\nsamples = 469\nvalue = [0, 0, 469]\nclass = win", fillcolor="#8139e5"] ;
51 -> 52 ;
53 [label="entropy = 0.431\nsamples = 428\nvalue = [24, 7, 397]\nclass = win", fillcolor="#8b48e7"] ;
51 -> 53 ;
54 [label="d1 <= 0.5\nentropy = 0.943\nsamples = 6385\nvalue = [524, 814, 5047]\nclass = win", fillcolor="#9f69eb"] ;
50 -> 54 ;
55 [label="entropy = 0.818\nsamples = 5276\nvalue = [400, 483, 4393]\nclass = win", fillcolor="#985dea"] ;
54 -> 55 ;
56 [label="entropy = 1.323\nsamples = 1109\nvalue = [124, 331, 654]\nclass = win", fillcolor="#cbadf4"] ;
54 -> 56 ;
57 [label="d4 <= 0.5\nentropy = 1.5\nsamples = 488\nvalue = [96, 161, 231]\nclass = win", fillcolor="#e4d5f9"] ;
49 -> 57 ;
58 [label="a2 <= -0.5\nentropy = 1.476\nsamples = 436\nvalue = [96, 113, 227]\nclass = win", fillcolor="#d3b9f6"] ;
57 -> 58 ;
59 [label="entropy = 1.122\nsamples = 40\nvalue = [5, 29, 6]\nclass = loss", fillcolor="#79edaa"] ;
58 -> 59 ;
60 [label="entropy = 1.432\nsamples = 396\nvalue = [91, 84, 221]\nclass = win", fillcolor="#c9abf4"] ;
58 -> 60 ;
61 [label="b3 <= -0.5\nentropy = 0.391\nsamples = 52\nvalue = [0, 48, 4]\nclass = loss", fillcolor="#49e78c"] ;
57 -> 61 ;
62 [label="entropy = 0.0\nsamples = 1\nvalue = [0, 0, 1]\nclass = win", fillcolor="#8139e5"] ;
61 -> 62 ;
63 [label="entropy = 0.323\nsamples = 51\nvalue = [0, 48, 3]\nclass = loss", fillcolor="#45e789"] ;
61 -> 63 ;
64 [label="b1 <= -0.5\nentropy = 1.01\nsamples = 16241\nvalue = [1560, 2220, 12461]\nclass = win", fillcolor="#a36eec"] ;
0 -> 64 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
65 [label="d2 <= 0.5\nentropy = 1.224\nsamples = 7190\nvalue = [913, 1425, 4852]\nclass = win", fillcolor="#b489f0"] ;
64 -> 65 ;
66 [label="c3 <= 0.5\nentropy = 1.188\nsamples = 6349\nvalue = [860, 1071, 4418]\nclass = win", fillcolor="#af81ef"] ;
65 -> 66 ;
67 [label="c2 <= -0.5\nentropy = 1.135\nsamples = 5924\nvalue = [772, 889, 4263]\nclass = win", fillcolor="#ab7aee"] ;
66 -> 67 ;
68 [label="d3 <= 0.5\nentropy = 0.228\nsamples = 746\nvalue = [9, 14, 723]\nclass = win", fillcolor="#853fe6"] ;
67 -> 68 ;
69 [label="entropy = 0.162\nsamples = 735\nvalue = [5, 10, 720]\nclass = win", fillcolor="#843de6"] ;
68 -> 69 ;
70 [label="entropy = 1.573\nsamples = 11\nvalue = [4, 4, 3]\nclass = draw", fillcolor="#ffffff"] ;
68 -> 70 ;
71 [label="b2 <= -0.5\nentropy = 1.216\nsamples = 5178\nvalue = [763, 875, 3540]\nclass = win", fillcolor="#b184ef"] ;
67 -> 71 ;
72 [label="entropy = 0.815\nsamples = 1533\nvalue = [85, 177, 1271]\nclass = win", fillcolor="#995fea"] ;
71 -> 72 ;
73 [label="entropy = 1.334\nsamples = 3645\nvalue = [678, 698, 2269]\nclass = win", fillcolor="#bc95f1"] ;
71 -> 73 ;
74 [label="b2 <= 0.5\nentropy = 1.525\nsamples = 425\nvalue = [88, 182, 155]\nclass = loss", fillcolor="#ebfcf2"] ;
66 -> 74 ;
75 [label="c4 <= -0.5\nentropy = 1.532\nsamples = 361\nvalue = [78, 128, 155]\nclass = win", fillcolor="#f0e8fc"] ;
74 -> 75 ;
76 [label="entropy = 1.235\nsamples = 91\nvalue = [31, 6, 54]\nclass = win", fillcolor="#cfb3f5"] ;
75 -> 76 ;
77 [label="entropy = 1.488\nsamples = 270\nvalue = [47, 122, 101]\nclass = loss", fillcolor="#e6fcef"] ;
75 -> 77 ;
78 [label="g1 <= -0.5\nentropy = 0.625\nsamples = 64\nvalue = [10, 54, 0]\nclass = loss", fillcolor="#5eea98"] ;
74 -> 78 ;
79 [label="entropy = 0.0\nsamples = 14\nvalue = [0, 14, 0]\nclass = loss", fillcolor="#39e581"] ;
78 -> 79 ;
80 [label="entropy = 0.722\nsamples = 50\nvalue = [10, 40, 0]\nclass = loss", fillcolor="#6aeca0"] ;
78 -> 80 ;
81 [label="d3 <= -0.5\nentropy = 1.269\nsamples = 841\nvalue = [53, 354, 434]\nclass = win", fillcolor="#eadefb"] ;
65 -> 81 ;
82 [label="c1 <= 0.5\nentropy = 0.975\nsamples = 219\nvalue = [9, 46, 164]\nclass = win", fillcolor="#a978ed"] ;
81 -> 82 ;
83 [label="a2 <= -0.5\nentropy = 1.091\nsamples = 166\nvalue = [8, 44, 114]\nclass = win", fillcolor="#b78df0"] ;
82 -> 83 ;
84 [label="entropy = 1.405\nsamples = 33\nvalue = [4, 16, 13]\nclass = loss", fillcolor="#e1fbec"] ;
83 -> 84 ;
85 [label="entropy = 0.927\nsamples = 133\nvalue = [4, 28, 101]\nclass = win", fillcolor="#a775ed"] ;
83 -> 85 ;
86 [label="d4 <= 0.5\nentropy = 0.366\nsamples = 53\nvalue = [1, 2, 50]\nclass = win", fillcolor="#8845e7"] ;
82 -> 86 ;
87 [label="entropy = 0.146\nsamples = 48\nvalue = [0, 1, 47]\nclass = win", fillcolor="#843de6"] ;
86 -> 87 ;
88 [label="entropy = 1.371\nsamples = 5\nvalue = [1, 1, 3]\nclass = win", fillcolor="#c09cf2"] ;
86 -> 88 ;
89 [label="d1 <= 0.0\nentropy = 1.295\nsamples = 622\nvalue = [44, 308, 270]\nclass = loss", fillcolor="#eafcf1"] ;
81 -> 89 ;
90 [label="d3 <= 0.5\nentropy = 1.321\nsamples = 397\nvalue = [33, 161, 203]\nclass = win", fillcolor="#e9dcfa"] ;
89 -> 90 ;
91 [label="entropy = 1.317\nsamples = 306\nvalue = [32, 95, 179]\nclass = win", fillcolor="#cdb0f5"] ;
90 -> 91 ;
92 [label="entropy = 0.915\nsamples = 91\nvalue = [1, 66, 24]\nclass = loss", fillcolor="#83efb0"] ;
90 -> 92 ;
93 [label="c2 <= -0.5\nentropy = 1.135\nsamples = 225\nvalue = [11, 147, 67]\nclass = loss", fillcolor="#9bf2bf"] ;
89 -> 93 ;
94 [label="entropy = 1.005\nsamples = 40\nvalue = [1, 11, 28]\nclass = win", fillcolor="#b58bf0"] ;
93 -> 94 ;
95 [label="entropy = 1.027\nsamples = 185\nvalue = [10, 136, 39]\nclass = loss", fillcolor="#7beeab"] ;
93 -> 95 ;
96 [label="g1 <= -0.5\nentropy = 0.791\nsamples = 9051\nvalue = [647, 795, 7609]\nclass = win", fillcolor="#975cea"] ;
64 -> 96 ;
97 [label="c1 <= -0.5\nentropy = 1.096\nsamples = 2717\nvalue = [269, 463, 1985]\nclass = win", fillcolor="#aa79ed"] ;
96 -> 97 ;
98 [label="e2 <= -0.5\nentropy = 1.223\nsamples = 2117\nvalue = [253, 441, 1423]\nclass = win", fillcolor="#b58bf0"] ;
97 -> 98 ;
99 [label="d1 <= -0.5\nentropy = 0.416\nsamples = 182\nvalue = [6, 6, 170]\nclass = win", fillcolor="#8a46e7"] ;
98 -> 99 ;
100 [label="entropy = 1.0\nsamples = 6\nvalue = [0, 3, 3]\nclass = loss", fillcolor="#ffffff"] ;
99 -> 100 ;
101 [label="entropy = 0.338\nsamples = 176\nvalue = [6, 3, 167]\nclass = win", fillcolor="#8843e6"] ;
99 -> 101 ;
102 [label="d2 <= 0.5\nentropy = 1.269\nsamples = 1935\nvalue = [247, 435, 1253]\nclass = win", fillcolor="#ba93f1"] ;
98 -> 102 ;
103 [label="entropy = 1.242\nsamples = 1704\nvalue = [234, 332, 1138]\nclass = win", fillcolor="#b58bf0"] ;
102 -> 103 ;
104 [label="entropy = 1.254\nsamples = 231\nvalue = [13, 103, 115]\nclass = win", fillcolor="#f3ecfd"] ;
102 -> 104 ;
105 [label="d4 <= 0.5\nentropy = 0.403\nsamples = 600\nvalue = [16, 22, 562]\nclass = win", fillcolor="#8946e7"] ;
97 -> 105 ;
106 [label="b1 <= 0.5\nentropy = 0.32\nsamples = 572\nvalue = [16, 11, 545]\nclass = win", fillcolor="#8743e6"] ;
105 -> 106 ;
107 [label="entropy = 0.453\nsamples = 335\nvalue = [16, 9, 310]\nclass = win", fillcolor="#8b49e7"] ;
106 -> 107 ;
108 [label="entropy = 0.07\nsamples = 237\nvalue = [0, 2, 235]\nclass = win", fillcolor="#823be5"] ;
106 -> 108 ;
109 [label="d3 <= 0.0\nentropy = 0.967\nsamples = 28\nvalue = [0, 11, 17]\nclass = win", fillcolor="#d3b9f6"] ;
105 -> 109 ;
110 [label="entropy = 0.0\nsamples = 14\nvalue = [0, 0, 14]\nclass = win", fillcolor="#8139e5"] ;
109 -> 110 ;
111 [label="entropy = 0.75\nsamples = 14\nvalue = [0, 11, 3]\nclass = loss", fillcolor="#6feca3"] ;
109 -> 111 ;
112 [label="a2 <= -0.5\nentropy = 0.618\nsamples = 6334\nvalue = [378, 332, 5624]\nclass = win", fillcolor="#9051e8"] ;
96 -> 112 ;
113 [label="d3 <= 0.5\nentropy = 0.922\nsamples = 2424\nvalue = [236, 249, 1939]\nclass = win", fillcolor="#9d65eb"] ;
112 -> 113 ;
114 [label="c3 <= 0.5\nentropy = 0.839\nsamples = 2260\nvalue = [201, 191, 1868]\nclass = win", fillcolor="#995fea"] ;
113 -> 114 ;
115 [label="entropy = 0.734\nsamples = 2024\nvalue = [155, 134, 1735]\nclass = win", fillcolor="#9458e9"] ;
114 -> 115 ;
116 [label="entropy = 1.421\nsamples = 236\nvalue = [46, 57, 133]\nclass = win", fillcolor="#caabf4"] ;
114 -> 116 ;
117 [label="d1 <= 0.0\nentropy = 1.529\nsamples = 164\nvalue = [35, 58, 71]\nclass = win", fillcolor="#f0e7fc"] ;
113 -> 117 ;
118 [label="entropy = 1.426\nsamples = 130\nvalue = [20, 41, 69]\nclass = win", fillcolor="#d7c1f7"] ;
117 -> 118 ;
119 [label="entropy = 1.261\nsamples = 34\nvalue = [15, 17, 2]\nclass = loss", fillcolor="#eafcf2"] ;
117 -> 119 ;
120 [label="d3 <= 0.5\nentropy = 0.372\nsamples = 3910\nvalue = [142, 83, 3685]\nclass = win", fillcolor="#8945e7"] ;
112 -> 120 ;
121 [label="b1 <= 0.5\nentropy = 0.296\nsamples = 3590\nvalue = [98, 56, 3436]\nclass = win", fillcolor="#8742e6"] ;
120 -> 121 ;
122 [label="entropy = 0.416\nsamples = 2049\nvalue = [85, 51, 1913]\nclass = win", fillcolor="#8a47e7"] ;
121 -> 122 ;
123 [label="entropy = 0.102\nsamples = 1541\nvalue = [13, 5, 1523]\nclass = win", fillcolor="#823be5"] ;
121 -> 123 ;
124 [label="d1 <= 0.0\nentropy = 0.976\nsamples = 320\nvalue = [44, 27, 249]\nclass = win", fillcolor="#a16cec"] ;
120 -> 124 ;
125 [label="entropy = 0.785\nsamples = 254\nvalue = [22, 18, 214]\nclass = win", fillcolor="#975be9"] ;
124 -> 125 ;
126 [label="entropy = 1.406\nsamples = 66\nvalue = [22, 9, 35]\nclass = win", fillcolor="#dac4f7"] ;
124 -> 126 ;
}

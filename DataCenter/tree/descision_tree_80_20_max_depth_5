digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname="helvetica"] ;
edge [fontname="helvetica"] ;
0 [label="a1 <= 0.5\nentropy = 1.22\nsamples = 54045\nvalue = [5178, 13327, 35540]\nclass = win", fillcolor="#ba93f1"] ;
1 [label="g1 <= 0.5\nentropy = 1.278\nsamples = 37804\nvalue = [3618, 11107, 23079]\nclass = win", fillcolor="#c6a6f3"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label="d2 <= 0.5\nentropy = 1.315\nsamples = 26342\nvalue = [2418, 9196, 14728]\nclass = win", fillcolor="#d6bff7"] ;
1 -> 2 ;
3 [label="d1 <= -0.5\nentropy = 1.316\nsamples = 21459\nvalue = [2228, 6690, 12541]\nclass = win", fillcolor="#cdb1f5"] ;
2 -> 3 ;
4 [label="d3 <= 0.5\nentropy = 1.036\nsamples = 4395\nvalue = [333, 774, 3288]\nclass = win", fillcolor="#a876ed"] ;
3 -> 4 ;
5 [label="entropy = 0.913\nsamples = 3691\nvalue = [255, 491, 2945]\nclass = win", fillcolor="#9e67eb"] ;
4 -> 5 ;
6 [label="entropy = 1.386\nsamples = 704\nvalue = [78, 283, 343]\nclass = win", fillcolor="#ede3fb"] ;
4 -> 6 ;
7 [label="c3 <= 0.5\nentropy = 1.361\nsamples = 17064\nvalue = [1895, 5916, 9253]\nclass = win", fillcolor="#d9c4f7"] ;
3 -> 7 ;
8 [label="entropy = 1.332\nsamples = 14420\nvalue = [1567, 4554, 8299]\nclass = win", fillcolor="#cfb4f5"] ;
7 -> 8 ;
9 [label="entropy = 1.397\nsamples = 2644\nvalue = [328, 1362, 954]\nclass = loss", fillcolor="#cff9e1"] ;
7 -> 9 ;
10 [label="d3 <= -0.5\nentropy = 1.195\nsamples = 4883\nvalue = [190, 2506, 2187]\nclass = loss", fillcolor="#e8fcf0"] ;
2 -> 10 ;
11 [label="d1 <= 0.0\nentropy = 1.085\nsamples = 1539\nvalue = [45, 502, 992]\nclass = win", fillcolor="#c3a1f3"] ;
10 -> 11 ;
12 [label="entropy = 0.838\nsamples = 739\nvalue = [23, 122, 594]\nclass = win", fillcolor="#9f68eb"] ;
11 -> 12 ;
13 [label="entropy = 1.154\nsamples = 800\nvalue = [22, 380, 398]\nclass = win", fillcolor="#faf7fe"] ;
11 -> 13 ;
14 [label="d1 <= 0.0\nentropy = 1.17\nsamples = 3344\nvalue = [145, 2004, 1195]\nclass = loss", fillcolor="#b4f5d0"] ;
10 -> 14 ;
15 [label="entropy = 1.252\nsamples = 1788\nvalue = [99, 881, 808]\nclass = loss", fillcolor="#f0fdf6"] ;
14 -> 15 ;
16 [label="entropy = 0.989\nsamples = 1556\nvalue = [46, 1123, 387]\nclass = loss", fillcolor="#82efb0"] ;
14 -> 16 ;
17 [label="g2 <= -0.5\nentropy = 1.105\nsamples = 11462\nvalue = [1200, 1911, 8351]\nclass = win", fillcolor="#aa79ed"] ;
1 -> 17 ;
18 [label="d1 <= 0.5\nentropy = 1.356\nsamples = 3692\nvalue = [556, 929, 2207]\nclass = win", fillcolor="#c5a3f3"] ;
17 -> 18 ;
19 [label="g3 <= 0.5\nentropy = 1.283\nsamples = 2935\nvalue = [451, 581, 1903]\nclass = win", fillcolor="#b890f0"] ;
18 -> 19 ;
20 [label="entropy = 1.397\nsamples = 2004\nvalue = [355, 492, 1157]\nclass = win", fillcolor="#c8a8f4"] ;
19 -> 20 ;
21 [label="entropy = 0.918\nsamples = 931\nvalue = [96, 89, 746]\nclass = win", fillcolor="#9d65eb"] ;
19 -> 21 ;
22 [label="a1 <= -0.5\nentropy = 1.439\nsamples = 757\nvalue = [105, 348, 304]\nclass = loss", fillcolor="#ecfcf3"] ;
18 -> 22 ;
23 [label="entropy = 1.327\nsamples = 333\nvalue = [56, 208, 69]\nclass = loss", fillcolor="#97f1bd"] ;
22 -> 23 ;
24 [label="entropy = 1.36\nsamples = 424\nvalue = [49, 140, 235]\nclass = win", fillcolor="#d5bdf6"] ;
22 -> 24 ;
25 [label="d3 <= 0.5\nentropy = 0.943\nsamples = 7770\nvalue = [644, 982, 6144]\nclass = win", fillcolor="#9f68eb"] ;
17 -> 25 ;
26 [label="d2 <= -0.5\nentropy = 0.88\nsamples = 7282\nvalue = [548, 821, 5913]\nclass = win", fillcolor="#9c63eb"] ;
25 -> 26 ;
27 [label="entropy = 0.243\nsamples = 897\nvalue = [24, 7, 866]\nclass = win", fillcolor="#8540e6"] ;
26 -> 27 ;
28 [label="entropy = 0.943\nsamples = 6385\nvalue = [524, 814, 5047]\nclass = win", fillcolor="#9f69eb"] ;
26 -> 28 ;
29 [label="d4 <= 0.5\nentropy = 1.5\nsamples = 488\nvalue = [96, 161, 231]\nclass = win", fillcolor="#e4d5f9"] ;
25 -> 29 ;
30 [label="entropy = 1.476\nsamples = 436\nvalue = [96, 113, 227]\nclass = win", fillcolor="#d3b9f6"] ;
29 -> 30 ;
31 [label="entropy = 0.391\nsamples = 52\nvalue = [0, 48, 4]\nclass = loss", fillcolor="#49e78c"] ;
29 -> 31 ;
32 [label="b1 <= -0.5\nentropy = 1.01\nsamples = 16241\nvalue = [1560, 2220, 12461]\nclass = win", fillcolor="#a36eec"] ;
0 -> 32 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
33 [label="d2 <= 0.5\nentropy = 1.224\nsamples = 7190\nvalue = [913, 1425, 4852]\nclass = win", fillcolor="#b489f0"] ;
32 -> 33 ;
34 [label="c3 <= 0.5\nentropy = 1.188\nsamples = 6349\nvalue = [860, 1071, 4418]\nclass = win", fillcolor="#af81ef"] ;
33 -> 34 ;
35 [label="c2 <= -0.5\nentropy = 1.135\nsamples = 5924\nvalue = [772, 889, 4263]\nclass = win", fillcolor="#ab7aee"] ;
34 -> 35 ;
36 [label="entropy = 0.228\nsamples = 746\nvalue = [9, 14, 723]\nclass = win", fillcolor="#853fe6"] ;
35 -> 36 ;
37 [label="entropy = 1.216\nsamples = 5178\nvalue = [763, 875, 3540]\nclass = win", fillcolor="#b184ef"] ;
35 -> 37 ;
38 [label="b2 <= 0.5\nentropy = 1.525\nsamples = 425\nvalue = [88, 182, 155]\nclass = loss", fillcolor="#ebfcf2"] ;
34 -> 38 ;
39 [label="entropy = 1.532\nsamples = 361\nvalue = [78, 128, 155]\nclass = win", fillcolor="#f0e8fc"] ;
38 -> 39 ;
40 [label="entropy = 0.625\nsamples = 64\nvalue = [10, 54, 0]\nclass = loss", fillcolor="#5eea98"] ;
38 -> 40 ;
41 [label="d3 <= -0.5\nentropy = 1.269\nsamples = 841\nvalue = [53, 354, 434]\nclass = win", fillcolor="#eadefb"] ;
33 -> 41 ;
42 [label="c1 <= 0.5\nentropy = 0.975\nsamples = 219\nvalue = [9, 46, 164]\nclass = win", fillcolor="#a978ed"] ;
41 -> 42 ;
43 [label="entropy = 1.091\nsamples = 166\nvalue = [8, 44, 114]\nclass = win", fillcolor="#b78df0"] ;
42 -> 43 ;
44 [label="entropy = 0.366\nsamples = 53\nvalue = [1, 2, 50]\nclass = win", fillcolor="#8845e7"] ;
42 -> 44 ;
45 [label="d1 <= 0.0\nentropy = 1.295\nsamples = 622\nvalue = [44, 308, 270]\nclass = loss", fillcolor="#eafcf1"] ;
41 -> 45 ;
46 [label="entropy = 1.321\nsamples = 397\nvalue = [33, 161, 203]\nclass = win", fillcolor="#e9dcfa"] ;
45 -> 46 ;
47 [label="entropy = 1.135\nsamples = 225\nvalue = [11, 147, 67]\nclass = loss", fillcolor="#9bf2bf"] ;
45 -> 47 ;
48 [label="g1 <= -0.5\nentropy = 0.791\nsamples = 9051\nvalue = [647, 795, 7609]\nclass = win", fillcolor="#975cea"] ;
32 -> 48 ;
49 [label="c1 <= -0.5\nentropy = 1.096\nsamples = 2717\nvalue = [269, 463, 1985]\nclass = win", fillcolor="#aa79ed"] ;
48 -> 49 ;
50 [label="e2 <= -0.5\nentropy = 1.223\nsamples = 2117\nvalue = [253, 441, 1423]\nclass = win", fillcolor="#b58bf0"] ;
49 -> 50 ;
51 [label="entropy = 0.416\nsamples = 182\nvalue = [6, 6, 170]\nclass = win", fillcolor="#8a46e7"] ;
50 -> 51 ;
52 [label="entropy = 1.269\nsamples = 1935\nvalue = [247, 435, 1253]\nclass = win", fillcolor="#ba93f1"] ;
50 -> 52 ;
53 [label="d4 <= 0.5\nentropy = 0.403\nsamples = 600\nvalue = [16, 22, 562]\nclass = win", fillcolor="#8946e7"] ;
49 -> 53 ;
54 [label="entropy = 0.32\nsamples = 572\nvalue = [16, 11, 545]\nclass = win", fillcolor="#8743e6"] ;
53 -> 54 ;
55 [label="entropy = 0.967\nsamples = 28\nvalue = [0, 11, 17]\nclass = win", fillcolor="#d3b9f6"] ;
53 -> 55 ;
56 [label="a2 <= -0.5\nentropy = 0.618\nsamples = 6334\nvalue = [378, 332, 5624]\nclass = win", fillcolor="#9051e8"] ;
48 -> 56 ;
57 [label="d3 <= 0.5\nentropy = 0.922\nsamples = 2424\nvalue = [236, 249, 1939]\nclass = win", fillcolor="#9d65eb"] ;
56 -> 57 ;
58 [label="entropy = 0.839\nsamples = 2260\nvalue = [201, 191, 1868]\nclass = win", fillcolor="#995fea"] ;
57 -> 58 ;
59 [label="entropy = 1.529\nsamples = 164\nvalue = [35, 58, 71]\nclass = win", fillcolor="#f0e7fc"] ;
57 -> 59 ;
60 [label="d3 <= 0.5\nentropy = 0.372\nsamples = 3910\nvalue = [142, 83, 3685]\nclass = win", fillcolor="#8945e7"] ;
56 -> 60 ;
61 [label="entropy = 0.296\nsamples = 3590\nvalue = [98, 56, 3436]\nclass = win", fillcolor="#8742e6"] ;
60 -> 61 ;
62 [label="entropy = 0.976\nsamples = 320\nvalue = [44, 27, 249]\nclass = win", fillcolor="#a16cec"] ;
60 -> 62 ;
}
